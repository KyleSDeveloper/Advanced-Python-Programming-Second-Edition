{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KyleSDeveloper/Advanced-Python-Programming-Second-Edition/blob/main/08_Introduction_to_Classification_workset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBDfgfJY6X2F",
        "outputId": "3bbd98f4-c967-43f7-f3d2-5e790ce720f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics attrdict -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6FyQ11IDHTG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchmetrics\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "from attrdict import AttrDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVnQSeXZahJI"
      },
      "outputs": [],
      "source": [
        "# Maybe delete this. Not sure if I want to get into GPUs yet, that should be a separate lesson.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvKaTo03-UQ-"
      },
      "outputs": [],
      "source": [
        "# Load the train and validation data\n",
        "mnist_train = pd.read_csv('sample_data/mnist_train_small.csv', header=None)\n",
        "mnist_valid = pd.read_csv('sample_data/mnist_test.csv', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGuzgVZD9Zg9"
      },
      "outputs": [],
      "source": [
        "# Take a look at the data.\n",
        "# It looks like the first column is the label,\n",
        "# And columns 1 - 785 are pixels.\n",
        "print(mnist_train.shape)\n",
        "mnist_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9KSy4IBJsHN"
      },
      "outputs": [],
      "source": [
        "# What's the distribuiont of labels in the train set?\n",
        "display(mnist_train[0].value_counts().sort_index().plot.bar())\n",
        "display(mnist_train[0].value_counts(normalize=True).max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJHfKi8cJ985"
      },
      "outputs": [],
      "source": [
        "# What's the distribuion of labels in the validation set?\n",
        "display(mnist_valid[0].value_counts().sort_index().plot.bar())\n",
        "display(mnist_valid[0].value_counts(normalize=True).max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIYGoVRMx91l"
      },
      "outputs": [],
      "source": [
        "def show_number(row, ax=None):\n",
        "    \"\"\"\n",
        "    This function shows a row as an image, and titles it with the label.\n",
        "\n",
        "    Options:\n",
        "    * row: a row from either of the mnist_train or mnist_valid dataframes.\n",
        "    * ax: if not None, will plot the digit on the provided ax.\n",
        "        Otherwise, this function should create a figure and\n",
        "    \"\"\"\n",
        "    return_fig = ax == None\n",
        "    target, values = row.values[0], row.values[1:].reshape(28, 28)\n",
        "    if not ax:\n",
        "        fig, ax = plt.subplots()\n",
        "    ax.imshow(values, cmap='gray_r')\n",
        "    ax.set_title(target)\n",
        "\n",
        "    plt.close()\n",
        "    if return_fig:\n",
        "        return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjwuD3W7Ay7j"
      },
      "outputs": [],
      "source": [
        "show_number(mnist_train.sample(1).iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbhVnnjW-wHK"
      },
      "outputs": [],
      "source": [
        "def show_many(n_rows=3, n_cols=3):\n",
        "    \"\"\"\n",
        "    This function shows a number of images at a time, by default 9.\n",
        "    It takes a random sample of (n_rows * n_cols) of the training data to show.\n",
        "    \"\"\"\n",
        "    # Sample the training data\n",
        "    train_df_sample = mnist_train.sample(n_rows * n_cols)\n",
        "    # Create the figure\n",
        "    fig = plt.figure(figsize=(4*n_cols, 4*n_rows))\n",
        "    # For each row in the sample, plot the number\n",
        "    for i, (_, row) in enumerate(train_df_sample.iterrows()):\n",
        "        ax = fig.add_subplot(n_rows, n_cols, 1+i)\n",
        "        show_number(row, ax)\n",
        "    plt.close()\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAmtLzYP07er"
      },
      "outputs": [],
      "source": [
        "show_many()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CTuMZo532Kn"
      },
      "outputs": [],
      "source": [
        "# What are the min and max values of the data?\n",
        "mnist_train.loc[:, 1:].values.max(), \\\n",
        "mnist_train.loc[:, 1:].values.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYRHdIphKc2V"
      },
      "outputs": [],
      "source": [
        "plt.hist(mnist_train.loc[:, 1:].values.ravel())\n",
        "plt.ylabel('Number of pixels')\n",
        "plt.xlabel('Value')\n",
        "plt.yscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1A1BoEqQ3_YP"
      },
      "outputs": [],
      "source": [
        "# Let's scale all the data between 0 and 1.\n",
        "mnist_train_scaled = mnist_train.copy()\n",
        "mnist_train_scaled.loc[:, 1:] /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKUlrbHx4T3x"
      },
      "outputs": [],
      "source": [
        "mnist_valid_scaled = mnist_valid.copy()\n",
        "mnist_valid_scaled.loc[:, 1:] /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pk6BerUY4Rrg"
      },
      "outputs": [],
      "source": [
        "mnist_train_scaled.loc[:, 1:].values.max(), \\\n",
        "mnist_train_scaled.loc[:, 1:].values.min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoR-Esrkz90U"
      },
      "source": [
        "# Exercise 8.1\n",
        "\n",
        "Now that we've preprocessed our data, we require objects to feed data to our model.\n",
        "Using your knowledge about `torch` datasets, complete the `MnistDataset` class.\n",
        "Your `__getitem__` method should return a tuple of two values - the first is a vector of lenth 784 representing the pixel values of the image, and the second is an integer representing the label (0-9).\n",
        "Both items should be of type `torch.Tensor`.\n",
        "\n",
        "<!-- startquestion -->\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPtwZS5A2j9j"
      },
      "outputs": [],
      "source": [
        "class MnistDataset(Dataset):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH_VYzCz4irc"
      },
      "outputs": [],
      "source": [
        "# Create datasets from the dataframes\n",
        "train_ds = MnistDataset(mnist_train_scaled)\n",
        "valid_ds = MnistDataset(mnist_valid_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "du9MTd3B0_gX"
      },
      "outputs": [],
      "source": [
        "# Sanity check!\n",
        "_x, _y = train_ds[0]\n",
        "assert _x.shape[0] == mnist_train_scaled.shape[1] - 1\n",
        "assert _y == mnist_train_scaled.loc[0,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kweDlauk08tG"
      },
      "source": [
        "# Exercise 8.2\n",
        "\n",
        "Now that we've created our datasets, use them to create our train and validation dataloaders.\n",
        "Remember to shuffle your train dataloader but not your valid!\n",
        "\n",
        "<!-- startquestion -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VO4G7cPA4zQd"
      },
      "outputs": [],
      "source": [
        "# Create dataloaders from the datasets.\n",
        "# During the training phase, we need to keep both the activations\n",
        "# and the gradients in memory. However during the validation phase,\n",
        "# we don't have to store gradients so we can double the batch size!\n",
        "\n",
        "train_dl = None\n",
        "valid_dl = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jZFug0E3JcB"
      },
      "outputs": [],
      "source": [
        "def linear(in_features, out_features, dropout=0.2):\n",
        "    \"\"\"\n",
        "    Returns an nn.Sequential module that we want to repeat a lot.\n",
        "    The module contains a linear layer, ReLU activation, BatchNorm, and dropout.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXUhyeGN4nU-"
      },
      "outputs": [],
      "source": [
        "# Sanity check!\n",
        "assert len(linear(1,1)) == 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukf-1HXu2CyR"
      },
      "outputs": [],
      "source": [
        "# Define some parameters for the model\n",
        "class Config(AttrDict):\n",
        "    def __init__(self, num_input_features=28*28, n_hidden_layers=2, hidden_dim=256, n_labels=10):\n",
        "        self.num_input_features = num_input_features\n",
        "        self.n_hidden_layers = n_hidden_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_labels = n_labels\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sj4grtALSRi1"
      },
      "outputs": [],
      "source": [
        "def build_model(config):\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFTpRLFg5ela"
      },
      "outputs": [],
      "source": [
        "# instantiate the model\n",
        "model = build_model(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1c5ckLZTKyq"
      },
      "outputs": [],
      "source": [
        "# if the model's not on the GPU but it's available, put it there.\n",
        "print('Model device: ', next(model.parameters()).device)\n",
        "if not next(model.parameters()).is_cuda & torch.cuda.is_available():\n",
        "    print('Model is on CPU, but GPU is available. Putting model on GPU.')\n",
        "    model = model.to(config.device)\n",
        "    print('Model device: ', next(model.parameters()).device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0vDVxKo2jij"
      },
      "outputs": [],
      "source": [
        "# Sanity check!\n",
        "assert len(model) == config.n_hidden_layers + 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i32PHOveL5E8"
      },
      "outputs": [],
      "source": [
        "# Another sanity check: our model should be able to operate on a batch of data.\n",
        "for x_b, y_b in train_dl:\n",
        "    break\n",
        "model(x_b.to(config.device)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgqtKpau5RjN"
      },
      "outputs": [],
      "source": [
        "loss_func = ...\n",
        "opt = ...\n",
        "metric = torchmetrics.Accuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xOfbQ4T-L3S"
      },
      "outputs": [],
      "source": [
        "def train_step(x_b, y_b):\n",
        "    # Send x_b and y_b to the GPU, if available\n",
        "    x_b = x_b.to(config.device)\n",
        "    y_b = y_b.to(config.device)\n",
        "    # Generate yhat\n",
        "    yhat = ...\n",
        "    # Calculate the loss\n",
        "    loss = ...\n",
        "    # Calculate gradients\n",
        "\n",
        "    # Perform your update and zero out your gradients\n",
        "    opt\n",
        "    opt\n",
        "\n",
        "    # Update your accuracy metric. We'll give you this one!\n",
        "    batch_acc = metric(yhat.cpu().softmax(axis=1), y_b.cpu())\n",
        "\n",
        "    # Return the loss\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS45cCPv_gbo"
      },
      "outputs": [],
      "source": [
        "def validation_step(x_b, y_b):\n",
        "    # Send x_b and y_b to the GPU, if available\n",
        "    x_b = ...\n",
        "    y_b = ...\n",
        "    # Tell torch not to calculate gradients on the validation batch\n",
        "    with torch.no_grad():\n",
        "        # Generate yhat\n",
        "        yhat = ...\n",
        "        # Calculate the loss\n",
        "        loss = ...\n",
        "\n",
        "    # Ok, you've seen this before, you do it this time!\n",
        "    batch_acc = ...\n",
        "\n",
        "    # Return the loss\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gsDzYhJ5SpS"
      },
      "outputs": [],
      "source": [
        "N_EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjPF8YoZ5jxr"
      },
      "outputs": [],
      "source": [
        "train_losses_step = []\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "for epoch in range(N_EPOCHS):\n",
        "    # Training loop\n",
        "    model.train() # Put the model in train mode\n",
        "    train_loss_epoch = 0.\n",
        "    for x_b, y_b in train_dl:\n",
        "        loss = train_step(x_b, y_b)\n",
        "        train_loss_epoch += loss\n",
        "        train_losses_step.append(loss.item())\n",
        "\n",
        "    # Compute the train loss and accuracy for the epoch.\n",
        "    # The epoch loss is a little bit off if our final batch\n",
        "    # is a different size - we're going to ignore that for now,\n",
        "    # since higher-level libraries will solve this for us.\n",
        "    train_loss_epoch /= len(train_dl)\n",
        "    train_losses.append(train_loss_epoch.item())\n",
        "    train_acc = metric.compute()\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval() # Put the model in eval mode (affects dropout and batch norm)\n",
        "    val_loss_epoch = 0.\n",
        "    for x_b, y_b in valid_dl:\n",
        "        loss = validation_step(x_b, y_b)\n",
        "        val_loss_epoch += loss\n",
        "\n",
        "    val_loss_epoch /= len(valid_dl)\n",
        "    valid_acc = metric.compute()\n",
        "    valid_losses.append(val_loss_epoch.item())\n",
        "\n",
        "    print(f\"Epoch: {epoch}, Train loss: {train_loss_epoch:.04f} Train acc: {float(train_acc):.04f}, Valid loss: {val_loss_epoch} Valid Acc: {float(valid_acc):.04f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hnlh1c1SLur1"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(20,8))\n",
        "ax1, ax2 = axes\n",
        "ax1.plot(train_losses_step, label='Train Loss')\n",
        "ax2.plot(train_losses, label='Train Loss')\n",
        "ax2.plot(valid_losses, label='Valid Loss')\n",
        "ax1.legend()\n",
        "ax2.legend()\n",
        "ax1.set_xlabel('Step')\n",
        "ax1.set_ylabel('Cross Entropy Loss')\n",
        "ax2.set_xlabel('Epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Y-goUHmfMAo"
      },
      "outputs": [],
      "source": [
        "def show_preds(sample=None):\n",
        "    \"\"\"\n",
        "    Shows a actuals and inferences from a random sample of the validation dataset.\n",
        "    \"\"\"\n",
        "    # Sample a few images\n",
        "    if sample is None:\n",
        "        sample = mnist_valid_scaled.sample(9)\n",
        "    # Get the sample into a format we can feed into the model\n",
        "    x_b = torch.FloatTensor(sample.loc[:, 1:].values)\n",
        "    y_b = sample.loc[:,0].values\n",
        "\n",
        "    # Make inferences on the sample\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Get the inferences, apply softmax to convert to predicted probabilities,\n",
        "        # and use argmax to get the index of the highest probability.\n",
        "        # This is the digit!\n",
        "        preds = model(x_b.to(config.device)).softmax(dim=-1).argmax(dim=-1).cpu().numpy()\n",
        "\n",
        "    # Plot a 3x3 grid of digits, where the title\n",
        "    # contains the predictiona nd the actual value.\n",
        "    fig = plt.figure(figsize=(12, 12))\n",
        "    for i, (x, y, p) in enumerate(zip(x_b, y_b, preds)):\n",
        "        ax = fig.add_subplot(3, 3, 1+i)\n",
        "        ax.matshow(x.reshape(28, 28), cmap='Greys_r')\n",
        "        ax.set_title(f'Actual: {y}, Pred: {int(p)}')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "    fig.tight_layout()\n",
        "    plt.close()\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_f4JkNyC4X7"
      },
      "outputs": [],
      "source": [
        "show_preds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA7uKJcGcCoA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i3GFLl_cLeM"
      },
      "outputs": [],
      "source": [
        "probas = []\n",
        "preds = []\n",
        "losses = []\n",
        "ys = []\n",
        "model.eval()\n",
        "for x_b, y_b in valid_dl:\n",
        "    with torch.no_grad():\n",
        "        logits = model(x_b.to(config.device)).cpu()\n",
        "        _probas = logits.softmax(dim=-1).numpy()\n",
        "        _preds = _probas.argmax(axis=-1)\n",
        "        _losses = F.cross_entropy(logits, y_b, reduce=False)\n",
        "    probas.append(_probas)\n",
        "    preds.append(_preds)\n",
        "    losses.append(_losses.numpy())\n",
        "    ys.append(y_b.numpy())\n",
        "probas = np.vstack(probas)\n",
        "preds = np.concatenate(preds)\n",
        "losses = np.concatenate(losses)\n",
        "ys = np.concatenate(ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n0VSjh7GprO"
      },
      "outputs": [],
      "source": [
        "disp = ConfusionMatrixDisplay(confusion_matrix(ys, preds, normalize='true'), display_labels=range(10))\n",
        "cm_fig, ax = plt.subplots(figsize=(10,10))\n",
        "disp.plot(ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QnFFnG-HZ43"
      },
      "outputs": [],
      "source": [
        "print(classification_report(ys, preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k8CKxH3Khwr"
      },
      "outputs": [],
      "source": [
        "# Your code here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aZCjBKEL3Oy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "08_Introduction_to_Classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}